{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuarentenaDados Desafio Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK4TYmKJkj93",
        "colab_type": "text"
      },
      "source": [
        "# Desafio Quarentena Dados\n",
        "\n",
        "O desafio proposto ao final da semana de curso de Data Science promovida pela **Alura** consiste em propor um modelo de Machine Learning para prever as notas de linguagem do ENEM utilizando apenas as outras notas obtidas pelos participantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Tf16k5r9kX",
        "colab_type": "text"
      },
      "source": [
        "## Leitura dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opuo4prwYiKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "URI_TREINO = \"https://github.com/tgcsantos/quaretenadados/blob/master/DADOS_TREINO.csv?raw=true\"\n",
        "URI_TESTE = \"https://github.com/tgcsantos/quaretenadados/raw/master/DADOS_TESTE.csv\"\n",
        "URI_DESAFIOQT = \"https://github.com/tgcsantos/quaretenadados/raw/master/DESAFIOQT.csv\"\n",
        "\n",
        "dados_treino = pd.read_csv(URI_TREINO)\n",
        "dados_teste = pd.read_csv(URI_TESTE)\n",
        "dados_desafioqt = pd.read_csv(URI_DESAFIOQT)\n",
        "\n",
        "erro_treino = \"Erro ao carregar dados de treino\"\n",
        "erro_teste = \"Erro ao carregar dados de teste\"\n",
        "erro_desafioqt = \"Erro ao carregar dados de submissão\"\n",
        "\n",
        "assert dados_treino.shape == (150000, 5), erro_treino\n",
        "assert dados_teste.shape == (20000, 5), erro_teste\n",
        "assert dados_desafioqt.shape == (10000, 5), erro_desafioqt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo_gn-z4Ys78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coluna_label = 'NU_NOTA_LC'\n",
        "coluna_features = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']\n",
        "\n",
        "X_treino = dados_treino[coluna_features].to_numpy()\n",
        "Y_treino = dados_treino[coluna_label].to_numpy()\n",
        "X_teste = dados_teste[coluna_features].to_numpy()\n",
        "Y_teste = dados_teste[coluna_label].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSTL9OL8sR2U",
        "colab_type": "text"
      },
      "source": [
        "## Construção do Modelo\n",
        "\n",
        "Construi uma classe que realiza o processo de regressão em duas etapas:\n",
        "* Primeiro os alunos são classificados em grupos utilizando o método de K-means nas notas obtidas no ENEM;\n",
        "* Em seguida, ajusta algum modelo de Regressão para cada um dos grupos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdFC1jFXYzGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "\n",
        "class segmentationRegression:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.stdX = StandardScaler()\n",
        "    self.stdY = StandardScaler()\n",
        "\n",
        "    self.n_cluster = 5\n",
        "    self.kmeans = KMeans(n_clusters=self.n_cluster)\n",
        "\n",
        "    self.clusters = None\n",
        "    self.clusters_star = None\n",
        "\n",
        "    self.models = {}\n",
        "    for i in range(self.n_cluster):\n",
        "      self.models[str(i)] = MLPRegressor()\n",
        "\n",
        "    self.fitted = None\n",
        "    self.forecast = None\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    self.stdX.fit(X)\n",
        "    self.stdY.fit(Y.reshape(-1, 1))\n",
        "    X_hat = self.stdX.transform(X)\n",
        "    Y_hat = self.stdY.transform(Y.reshape(-1, 1))\n",
        "\n",
        "    self.kmeans.fit(X_hat)\n",
        "    self.clusters = self.kmeans.labels_\n",
        "\n",
        "    for i in range(self.n_cluster):\n",
        "      condition = self.clusters == i\n",
        "      self.models[str(i)].fit(X_hat[condition],np.ravel(Y_hat[condition]))\n",
        "    \n",
        "    temp = []\n",
        "    for x, cluster in zip(X_hat, self.clusters):\n",
        "      aux = self.models[str(cluster)].predict(x.reshape(1,4))\n",
        "      temp.append(self.stdY.inverse_transform(aux).item(0))\n",
        "    self.fitted = np.array(temp)\n",
        "    del temp, aux\n",
        "\n",
        "  def predict(self, X_star):\n",
        "    X_star_hat = self.stdX.transform(X_star)\n",
        "    self.clusters_star = self.kmeans.predict(X_star_hat)\n",
        "\n",
        "    temp = []\n",
        "    for x, cluster in zip(X_star_hat, self.clusters_star):\n",
        "      aux = self.models[str(cluster)].predict(x.reshape(1,4))\n",
        "      temp.append(self.stdY.inverse_transform(aux).item(0))\n",
        "    self.forecast = np.array(temp)\n",
        "    del temp, aux"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k4KxzVesVyp",
        "colab_type": "text"
      },
      "source": [
        "## Aplicação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddjLxDKxJic6",
        "colab_type": "code",
        "outputId": "d81f7baa-e05c-4671-f075-aade0326bbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Avaliação do modelo\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "SR = segmentationRegression()\n",
        "SR.fit(X_treino, Y_treino)\n",
        "SR.predict(X_teste)\n",
        "SR_predicoes = SR.forecast\n",
        "\n",
        "avaliacao_SR = mean_squared_error(Y_teste, SR_predicoes)\n",
        "\n",
        "print(f\"Minha avaliação nos dados de teste foi de {avaliacao_SR}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minha avaliação nos dados de teste foi de 2051.1617031544456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbLJ8j1mP7dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#atribuir ao MODELO o nome do seu melhor modelo\n",
        "from google.colab import files\n",
        "\n",
        "MODELO = SR\n",
        "X_desafioqt = dados_desafioqt[coluna_features].to_numpy()\n",
        "SR.predict(X_desafioqt)\n",
        "predicao_desafioqt = SR.forecast\n",
        "\n",
        "\n",
        "desafio_df = pd.DataFrame(dados_desafioqt.ID)\n",
        "desafio_df[coluna_label] = predicao_desafioqt\n",
        "\n",
        "#NÃO TROCAR O NOME DO ARQUIVO DE SAÍDA (PREDICAO_DESAFIO)\n",
        "desafio_df.to_csv('PREDICAO_DESAFIOQT.csv', index=False) \n",
        "files.download('PREDICAO_DESAFIOQT.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}